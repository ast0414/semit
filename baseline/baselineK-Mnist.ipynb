{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers,regularizers\n",
    "\n",
    "from skimage import transform\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_batch(imgs):\n",
    "    # A function to resize a batch of MNIST images to (32, 32)\n",
    "    # Args:\n",
    "    #   imgs: a numpy array of size [batch_size, 28 X 28].\n",
    "    # Returns:\n",
    "    #   a numpy array of size [batch_size, 32, 32].\n",
    "    imgs = imgs.reshape((-1, 28, 28, 1))\n",
    "    resized_imgs = np.zeros((imgs.shape[0], 32, 32, 1))\n",
    "    for i in range(imgs.shape[0]):\n",
    "        resized_imgs[i, ..., 0] = transform.resize(imgs[i, ..., 0], (32, 32))\n",
    "    return resized_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please download dataset from git-lfs before running\n",
    "with open('kannada_semi_1pct.pkl', 'rb') as f:\n",
    "    kannada_semi = pickle.load(f)\n",
    "kannada_x_train_labeled = kannada_semi[\"x_train_labeled\"]\n",
    "kannada_y_train_labeled = kannada_semi[\"y_train_labeled\"]\n",
    "\n",
    "kannada_x_train_unlabeled = kannada_semi[\"x_train_unlabeled\"]\n",
    "kannada_y_train_unlabeled = kannada_semi[\"y_train_unlabeled\"]\n",
    "\n",
    "kannada_x_train = np.concatenate((kannada_x_train_labeled, kannada_x_train_unlabeled), axis=0)\n",
    "kannada_y_train = np.concatenate((kannada_y_train_labeled, kannada_y_train_unlabeled), axis=0)\n",
    "\n",
    "kannada_x_val = kannada_semi[\"x_val\"]\n",
    "kannada_y_val = kannada_semi[\"y_val\"]\n",
    "\n",
    "kannada_x_test = kannada_semi['x_test']\n",
    "kannada_y_test = kannada_semi['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please download dataset from git-lfs before running\n",
    "with open('dig_test.pkl', 'rb') as f:\n",
    "    dig_test = pickle.load(f)\n",
    "dig_x_test = dig_test['x_test']\n",
    "dig_y_test = dig_test['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kannada-MNIST Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping K-MNIST data from (28,28) to (32,32)\n",
    "\n",
    "# kannada_x_train_labeled = resize_batch(kannada_x_train_labeled)\n",
    "# kannada_x_train_unlabeled = resize_batch(kannada_x_train_unlabeled)\n",
    "\n",
    "kannada_x_train = resize_batch(kannada_x_train)\n",
    "kannada_x_val = resize_batch(kannada_x_val)\n",
    "kannada_x_test = resize_batch(kannada_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Dig-MNIST data from (28,28) to (32,32)\n",
    "dig_x_test = resize_batch(dig_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = Sequential()\n",
    "\n",
    "bmodel.add(layers.Conv2D(32, (4,4), strides=2, padding='same', activation=tf.nn.leaky_relu, input_shape=(32, 32, 1)))\n",
    "# bmodel.add(layers.LeakyReLU(alpha=0.2))\n",
    "bmodel.add(layers.Dropout(0.5))\n",
    "\n",
    "bmodel.add(layers.Conv2D(64, (4,4), strides=2, padding='same', activation=tf.nn.leaky_relu))\n",
    "# bmodel.add(layers.LeakyReLU(alpha=0.2))\n",
    "bmodel.add(layers.Dropout(0.5))\n",
    "\n",
    "bmodel.add(layers.Conv2D(128, (4,4), strides=2, padding='same', activation=tf.nn.leaky_relu))\n",
    "# bmodel.add(layers.LeakyReLU(alpha=0.2))\n",
    "bmodel.add(layers.Dropout(0.5))\n",
    "\n",
    "bmodel.add(layers.Conv2D(256, (4,4), strides=2, padding='same', activation=tf.nn.leaky_relu))\n",
    "# bmodel.add(layers.LeakyReLU(alpha=0.2))\n",
    "bmodel.add(layers.Dropout(0.5))\n",
    "\n",
    "bmodel.add(layers.Conv2D(512, (4,4), strides=2, padding='same', activation=tf.nn.leaky_relu))\n",
    "# bmodel.add(layers.LeakyReLU(alpha=0.2))\n",
    "bmodel.add(layers.Dropout(0.5))\n",
    "\n",
    "bmodel.add(layers.Flatten())\n",
    "bmodel.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 302s 5ms/step - loss: 0.1670 - accuracy: 0.9481 - val_loss: 0.0566 - val_accuracy: 0.9820\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 273s 5ms/step - loss: 0.1216 - accuracy: 0.9637 - val_loss: 0.0413 - val_accuracy: 0.9876\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 279s 5ms/step - loss: 0.1188 - accuracy: 0.9661 - val_loss: 0.0392 - val_accuracy: 0.9882\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 284s 5ms/step - loss: 0.1138 - accuracy: 0.9668 - val_loss: 0.0299 - val_accuracy: 0.9900\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 301s 5ms/step - loss: 0.1102 - accuracy: 0.9681 - val_loss: 0.0417 - val_accuracy: 0.9872\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 273s 5ms/step - loss: 0.1145 - accuracy: 0.9673 - val_loss: 0.0450 - val_accuracy: 0.9868\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 274s 5ms/step - loss: 0.1130 - accuracy: 0.9692 - val_loss: 0.0379 - val_accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 284s 5ms/step - loss: 0.1181 - accuracy: 0.9669 - val_loss: 0.0362 - val_accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 278s 5ms/step - loss: 0.1148 - accuracy: 0.9682 - val_loss: 0.0311 - val_accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 277s 5ms/step - loss: 0.1187 - accuracy: 0.9677 - val_loss: 0.0309 - val_accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4f5b6f3750>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "bmodel.fit(x=kannada_x_train, y=kannada_y_train, validation_data=(kannada_x_val, kannada_y_val), epochs=10)\n",
    "# change to 5 epochs for future trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-MNIST baseline model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 12s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17482808328717947, 0.9532999992370605]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmodel.evaluate(kannada_x_test, kannada_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model evaluation on Dig-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10240/10240 [==============================] - 13s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8050895781023428, 0.725878894329071]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmodel.evaluate(dig_x_test, dig_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
